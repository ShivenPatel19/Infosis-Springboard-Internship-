# import cv2
# import numpy as np

# # Load the video
# cap = cv2.VideoCapture('input/video.mp4')

# # Get video properties
# frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
# frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
# fps = int(cap.get(cv2.CAP_PROP_FPS))

# # Initialize VideoWriter
# out = cv2.VideoWriter('output/sparse_optical_flow_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

# # Parameters for Lucas-Kanade optical flow
# lk_params = dict(winSize=(15, 15), maxLevel=2,
#                  criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# # Parameters for Shi-Tomasi corner detection
# feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# # Read the first frame and find corners
# ret, old_frame = cap.read()
# old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)
# p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# # Create a mask for drawing
# mask = np.zeros_like(old_frame)

# while cap.isOpened():
#     ret, frame = cap.read()
#     if not ret:
#         break

#     frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

#     # Calculate optical flow
#     p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

#     # Select good points
#     good_new = p1[st == 1]
#     good_old = p0[st == 1]

#     # Draw the tracks
#     for i, (new, old) in enumerate(zip(good_new, good_old)):
#         a, b = new.ravel()
#         c, d = old.ravel()
#         mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)
#         frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 0, 255), -1)

#     img = cv2.add(frame, mask)

#     # Write the frame to the output video
#     out.write(img)

#     # Display the frame (optional)
#     # cv2.imshow('Sparse Optical Flow', img)

#     # Update the previous frame and points
#     old_gray = frame_gray.copy()
#     p0 = good_new.reshape(-1, 1, 2)

#     # if cv2.waitKey(1) & 0xFF == ord('q'):
#     #     break

# cap.release()
# out.release()
# cv2.destroyAllWindows()

import cv2
import numpy as np

# Load the video
cap = cv2.VideoCapture('input/Adv-IP.mp4')

# Get video properties
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Initialize VideoWriter
out = cv2.VideoWriter('output/sparse_optical_flow_output2.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

# Parameters for Lucas-Kanade optical flow
lk_params = dict(winSize=(15, 15), maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Parameters for Shi-Tomasi corner detection
feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Read the first frame and find corners
ret, old_frame = cap.read()
if not ret:
    print("Error: Couldn't read the first frame.")
    cap.release()
    out.release()
    exit()

old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)

# Create a mask for drawing
mask = np.zeros_like(old_frame)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calculate optical flow if there are points to track
    if p0 is not None:
        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

        # Check if p1 and st are valid
        if p1 is not None and st is not None:
            good_new = p1[st == 1]
            good_old = p0[st == 1]

            # Draw the tracks
            for i, (new, old) in enumerate(zip(good_new, good_old)):
                a, b = new.ravel()
                c, d = old.ravel()
                mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)
                frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 0, 255), -1)

            img = cv2.add(frame, mask)

            # Update the previous frame and points
            old_gray = frame_gray.copy()
            p0 = good_new.reshape(-1, 1, 2)
        else:
            # Reinitialize feature points if tracking is lost
            p0 = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)
    else:
        # Detect new features if no points are left to track
        p0 = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)
        img = frame

    # Write the frame to the output video
    out.write(img)

    # Display the frame (optional)
    # cv2.imshow('Sparse Optical Flow', img)

    # if cv2.waitKey(1) & 0xFF == ord('q'):
    #     break

cap.release()
out.release()
cv2.destroyAllWindows()
